import { serve } from "https://deno.land/std@0.168.0/http/server.ts"
import { createClient } from 'https://esm.sh/@supabase/supabase-js@2'

const corsHeaders = {
  'Access-Control-Allow-Origin': '*',
  'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type',
}

serve(async (req) => {
  if (req.method === 'OPTIONS') {
    return new Response(null, { headers: corsHeaders })
  }

  try {
    const { promptId, projectId, userMessage, conversationHistory } = await req.json()

    console.log('ü§ñ G√©n√©ration r√©ponse IA:', {
      promptId,
      projectId,
      messageLength: userMessage?.length || 0
    })

    const supabaseClient = createClient(
      Deno.env.get('SUPABASE_URL') ?? '',
      Deno.env.get('SUPABASE_SERVICE_ROLE_KEY') ?? '',
      {
        auth: {
          autoRefreshToken: false,
          persistSession: false
        }
      }
    )

    // 1. R√©cup√©rer le prompt IA
    const { data: prompt, error: promptError } = await supabaseClient
      .from('prompts_ia')
      .select('name, context, prompt, active')
      .eq('id', promptId)
      .eq('active', true)
      .single()

    if (promptError || !prompt) {
      console.error('‚ùå Prompt IA non trouv√©:', promptError)
      return new Response(JSON.stringify({
        success: false,
        error: 'Prompt IA non configur√©'
      }), {
        headers: { ...corsHeaders, 'Content-Type': 'application/json' },
        status: 400,
      })
    }

    console.log('‚úÖ Prompt IA trouv√©:', prompt.name)

    // 2. R√©cup√©rer le contexte enrichi du projet si disponible
    let projectContext = ''
    let vectorSearchResults = []

    if (projectId) {
      try {
        // R√©cup√©rer le contexte structur√© du projet
        const { data: contextData, error: contextError } = await supabaseClient
          .rpc('get_project_context_for_ai', {
            p_project_id: projectId,
            p_limit: 10
          })

        if (contextData && !contextError) {
          // Construire un r√©sum√© du contexte projet
          const ctx = contextData
          projectContext = `\n\nCONTEXTE DU PROJET:
`

          if (ctx.project_info) {
            projectContext += `Projet: ${ctx.project_info.title}\n`
            projectContext += `Description: ${ctx.project_info.description || 'Non sp√©cifi√©e'}\n`
            projectContext += `Statut: ${ctx.project_info.status}\n`
          }

          if (ctx.team_members && ctx.team_members.length > 0) {
            projectContext += `\n√âquipe: ${ctx.team_members.map(m =>
              m.is_ai ? `${m.profile_name} (IA)` : m.candidate_name
            ).join(', ')}\n`
          }

          if (ctx.active_tasks && ctx.active_tasks.length > 0) {
            projectContext += `\nT√¢ches actives: ${ctx.active_tasks.length}\n`
            ctx.active_tasks.slice(0, 3).forEach(task => {
              projectContext += `- ${task.title} (${task.status})\n`
            })
          }

          if (ctx.recent_documents && ctx.recent_documents.length > 0) {
            projectContext += `\nDocuments r√©cents: ${ctx.recent_documents.length} fichiers\n`
          }
        }

        // Si OpenAI est configur√©, faire une recherche vectorielle
        if (Deno.env.get('OPENAI_API_KEY') && userMessage.length > 10) {
          // G√©n√©rer l'embedding de la question
          const queryEmbedding = await generateQueryEmbedding(userMessage)

          if (queryEmbedding) {
            // Rechercher dans les embeddings du projet
            const { data: searchResults, error: searchError } = await supabaseClient
              .rpc('search_project_embeddings', {
                p_project_id: projectId,
                p_query_embedding: queryEmbedding,
                p_match_threshold: 0.7,
                p_match_count: 5
              })

            if (searchResults && searchResults.length > 0 && !searchError) {
              vectorSearchResults = searchResults
              projectContext += `\n\nCONTENU PERTINENT DU PROJET:\n`
              searchResults.forEach((result, idx) => {
                projectContext += `\n[${idx + 1}] ${result.content_type}: ${result.content.substring(0, 200)}...\n`
                projectContext += `(Pertinence: ${(result.similarity * 100).toFixed(1)}%)\n`
              })
            }
          }
        }
      } catch (error) {
        console.error('‚ö†Ô∏è Erreur r√©cup√©ration contexte projet:', error)
        // Continuer sans le contexte projet
      }
    }

    // 3. Construire le contexte de conversation avec m√©moire compl√®te
    const historyText = conversationHistory
      ?.slice(0, 8) // Utiliser jusqu'√† 8 messages pour plus de contexte
      ?.map(msg => {
        const senderName = msg.sender_name || msg.sender_email?.split('@')[0] || 'Utilisateur'
        return `${senderName}: ${msg.content}`
      })
      ?.join('\n') || ''

    // 4. Construire le prompt complet avec m√©moire de conversation et contexte projet
    const systemPrompt = `${prompt.prompt}${projectContext}

IMPORTANT - M√©moire de conversation:
Vous avez une conversation continue avec cet utilisateur. Vous devez :
- Vous souvenir du contexte et des sujets pr√©c√©demment discut√©s
- Faire r√©f√©rence aux √©changes pr√©c√©dents quand c'est pertinent
- Maintenir la coh√©rence dans vos r√©ponses
- Adapter votre ton en fonction de la relation √©tablie

Historique de la conversation (du plus ancien au plus r√©cent):
${historyText}

Nouveau message de l'utilisateur: ${userMessage}

Instructions:
- R√©pondez en fran√ßais
- Tenez compte de l'historique de conversation
- Soyez coh√©rent avec vos r√©ponses pr√©c√©dentes
- Si vous produisez un contenu long (article, document), structurez-le clairement
- Adoptez un ton sympathique et d√©contract√©, comme un coll√®gue bienveillant
- Utilisez le pr√©nom de l'utilisateur naturellement (sans trop insister)
- Ajoutez des expressions naturelles et chaleureuses
- √âvitez les formulations trop formelles ("Monsieur/Madame")
- Soyez enthousiaste et positif tout en restant professionnel

IMPORTANT - Gestion des livrables:
Si l'utilisateur demande un livrable (article, planning, guide, rapport, documentation, etc.):
1. Produisez le contenu demand√© de mani√®re compl√®te et structur√©e
2. √Ä la fin, demandez TOUJOURS : "üìÅ Souhaitez-vous que je sauvegarde ce document dans votre Drive projet (dossier IA) au format Word (.docx) ?"
3. Si l'utilisateur r√©pond oui/ok/d'accord/bien s√ªr/absolument/avec plaisir, votre r√©ponse doit TOUJOURS terminer par:
   [SAVE_TO_DRIVE: nom_du_fichier.docx]
   o√π nom_du_fichier est un nom descriptif bas√© sur le contenu (ex: article_marketing_digital.docx, planning_projet_2025.docx)

IMPORTANT: Quand l'utilisateur confirme qu'il veut sauvegarder (avec oui, ok, d'accord, etc.), vous DEVEZ obligatoirement ajouter le tag [SAVE_TO_DRIVE: nom_fichier.docx] √† la FIN de votre message, apr√®s tout le contenu.`

    // 5. Appel √† OpenAI
    const openaiApiKey = Deno.env.get('OPENAI_API_KEY')

    if (!openaiApiKey) {
      console.warn('‚ö†Ô∏è Cl√© OpenAI non configur√©e, utilisation d\'une r√©ponse simul√©e')

      // R√©ponse simul√©e pour le d√©veloppement avec contexte projet
      const simulatedResponse = generateSimulatedResponse(userMessage, prompt.name, historyText, projectContext)

      return new Response(JSON.stringify({
        success: true,
        response: simulatedResponse,
        promptUsed: prompt.name,
        simulated: true
      }), {
        headers: { ...corsHeaders, 'Content-Type': 'application/json' },
      })
    }

    // Appel r√©el OpenAI
    const openaiResponse = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${openaiApiKey}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: 'gpt-4',
        messages: [
          {
            role: 'system',
            content: systemPrompt
          }
        ],
        max_tokens: 1500,
        temperature: 0.7,
      }),
    })

    if (!openaiResponse.ok) {
      throw new Error('OpenAI API error: ' + openaiResponse.statusText)
    }

    const openaiData = await openaiResponse.json()
    const aiResponse = openaiData.choices?.[0]?.message?.content

    if (!aiResponse) {
      throw new Error('Aucune r√©ponse g√©n√©r√©e par OpenAI')
    }

    console.log('‚úÖ R√©ponse IA g√©n√©r√©e:', aiResponse.length, 'caract√®res')

    return new Response(JSON.stringify({
      success: true,
      response: aiResponse,
      promptUsed: prompt.name,
      tokensUsed: openaiData.usage?.total_tokens || 0
    }), {
      headers: { ...corsHeaders, 'Content-Type': 'application/json' },
    })

  } catch (error) {
    console.error('‚ùå Erreur g√©n√©ration IA:', error)
    return new Response(JSON.stringify({
      success: false,
      error: error.message
    }), {
      headers: { ...corsHeaders, 'Content-Type': 'application/json' },
      status: 500,
    })
  }
})

// Fonction pour g√©n√©rer l'embedding d'une requ√™te
async function generateQueryEmbedding(text: string): Promise<number[] | null> {
  const openaiApiKey = Deno.env.get('OPENAI_API_KEY')

  if (!openaiApiKey) {
    return null
  }

  try {
    const response = await fetch('https://api.openai.com/v1/embeddings', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${openaiApiKey}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: 'text-embedding-3-small',
        input: text.substring(0, 8000), // Limiter la taille
      }),
    })

    if (!response.ok) {
      console.error('‚ùå Erreur g√©n√©ration embedding requ√™te')
      return null
    }

    const data = await response.json()
    return data.data?.[0]?.embedding || null
  } catch (error) {
    console.error('‚ùå Erreur embedding:', error)
    return null
  }
}

// Fonction pour g√©n√©rer une r√©ponse simul√©e pendant le d√©veloppement
function generateSimulatedResponse(userMessage: string, promptName: string, historyText: string, projectContext: string = ''): string {
  console.log('üîç [generateSimulatedResponse] Analyse:', {
    userMessage: userMessage.slice(0, 100),
    hasAskedAboutSaving: historyText.includes('Souhaitez-vous que je sauvegarde'),
    historyLength: historyText.length
  });

  // V√©rifier si l'utilisateur confirme la sauvegarde
  const confirmWords = ['oui', 'ok', "d'accord", 'bien s√ªr', 'absolument', 'avec plaisir', 'parfait', 'super', 'yes', 'allez-y', 'go', 'allons-y', 'enregistre'];
  const isConfirmation = confirmWords.some(word => userMessage.toLowerCase().includes(word));
  const hasAskedAboutSaving = historyText.includes('Souhaitez-vous que je sauvegarde') ||
                               historyText.includes('sauvegarde ce document') ||
                               historyText.includes('sauvegarde cet article') ||
                               historyText.includes('enregistrerai sous le nom') ||
                               userMessage.toLowerCase().includes('enregistrer');

  console.log('‚úÖ [generateSimulatedResponse] D√©tection confirmation:', {
    isConfirmation,
    hasAskedAboutSaving,
    matchedWords: confirmWords.filter(word => userMessage.toLowerCase().includes(word))
  });

  // Si c'est une confirmation de sauvegarde
  if (isConfirmation && hasAskedAboutSaving) {
    const timestamp = Date.now();
    // G√©n√©rer un nom de fichier plus descriptif bas√© sur le contexte
    let fileName = 'document_ia_' + timestamp + '.docx';

    // Essayer de deviner le type de document depuis l'historique
    if (historyText.includes('article') || historyText.includes('blog')) {
      fileName = 'article_' + timestamp + '.docx';
    } else if (historyText.includes('planning') || historyText.includes('calendrier')) {
      fileName = 'planning_' + timestamp + '.xlsx'; // Excel pour les plannings
    } else if (historyText.includes('guide') || historyText.includes('manuel')) {
      fileName = 'guide_' + timestamp + '.pdf'; // PDF pour les guides
    } else if (historyText.includes('rapport') || historyText.includes('analyse')) {
      fileName = 'rapport_' + timestamp + '.pdf'; // PDF pour les rapports
    } else if (historyText.includes('tableau') || historyText.includes('donn√©es') || historyText.includes('statistiques')) {
      fileName = 'donnees_' + timestamp + '.csv'; // CSV pour les donn√©es
    } else if (historyText.includes('pr√©sentation') || historyText.includes('slides')) {
      fileName = 'presentation_' + timestamp + '.docx'; // Word pour les pr√©sentations
    }

    console.log('üíæ [generateSimulatedResponse] G√©n√©ration avec SAVE_TO_DRIVE:', fileName);

    // IMPORTANT: Le tag SAVE_TO_DRIVE doit √™tre √† la FIN du message
    const responseMessage = 'Super ! üéâ Je m\'occupe de sauvegarder √ßa pour vous !\n\n' +
                          'üìÅ Le fichier "' + fileName + '" est maintenant disponible dans le dossier IA de votre Drive.\n\n' +
                          'Vous pouvez le t√©l√©charger, le modifier ou le partager avec l\'√©quipe.\n\n' +
                          '‚úÖ Document sauvegard√© avec succ√®s !\n\n' +
                          '[SAVE_TO_DRIVE: ' + fileName + ']';

    console.log('üîç [generateSimulatedResponse] R√©ponse avec tag:', responseMessage.includes('[SAVE_TO_DRIVE:'));
    return responseMessage;
  }
  // V√©rifier si la demande concerne un livrable (article, guide, etc.)
  const isDeliverableRequest = userMessage.toLowerCase().includes('article') ||
                               userMessage.toLowerCase().includes('guide') ||
                               userMessage.toLowerCase().includes('rapport') ||
                               userMessage.toLowerCase().includes('document') ||
                               userMessage.toLowerCase().includes('planning') ||
                               userMessage.toLowerCase().includes('pr√©sentation') ||
                               userMessage.toLowerCase().includes('r√©dige') ||
                               userMessage.toLowerCase().includes('√©cris') ||
                               userMessage.toLowerCase().includes('cr√©e');

  const responses = {
    'Concepteur r√©dacteur IA': [
      'Ah, un article sur "' + userMessage.slice(0, 50) + '" ? Avec plaisir ! üòä\n\n# ' + userMessage + '\n\n## Introduction\nAlors, parlons de √ßa ! ' + userMessage + ', c\'est un sujet vraiment int√©ressant qui m√©rite qu\'on s\'y attarde.' + (projectContext ? '\n\nDans le contexte de votre projet, j\'ai not√© quelques √©l√©ments pertinents que je vais int√©grer.' : '') + '\n\n## Les points cl√©s\n- üéØ D\'abord, analysons le contexte\n- üí° Ensuite, explorons les solutions possibles\n- üöÄ Et enfin, passons √† l\'action !\n\n## Pour conclure\nJ\'esp√®re que cet article vous aide ! N\'h√©sitez pas si vous voulez que j\'approfondisse certains points.\n\n*R√©dig√© avec enthousiasme le ' + new Date().toLocaleDateString('fr-FR') + '* üéÜ\n\n' + (isDeliverableRequest ? 'üìÅ √áa vous dit que je sauvegarde ce document dans votre Drive ? (dossier IA, format Word)' : 'Autre chose ?'),

      'OK, let\'s go ! üöÄ\n\n# ' + userMessage + '\n\n## Alors, qu\'est-ce qu\'on a l√† ?\n\n' + userMessage + '... Int√©ressant ! Laissez-moi vous proposer quelque chose de sympa.\n\n### Voici mon plan d\'attaque :\n1. **D\'abord** : On clarifie l\'objectif üéØ\n2. **Ensuite** : On explore les options üîç\n3. **Enfin** : On passe √† l\'action ! üí™\n\n### En r√©sum√©\nJ\'ai h√¢te de voir ce que √ßa va donner ! Vous me dites si √ßa vous convient ?\n\n' + (isDeliverableRequest ? 'üìÅ Je peux sauvegarder tout √ßa dans votre Drive si vous voulez (format Word, dans le dossier IA) ?' : 'Besoin d\'autre chose ? Je suis l√† ! üôÇ'),

      'üìù **Document r√©dactionnel g√©n√©r√©**\n\n# ' + userMessage + '\n\n## Contenu structur√©\n\nJe vais cr√©er un contenu professionnel r√©pondant √† votre demande :\n\n### Section 1 : Pr√©sentation\n- Contexte : ' + userMessage.slice(0, 100) + '\n- Objectifs d√©finis\n- Approche m√©thodologique\n\n### Section 2 : D√©veloppement\n- Analyse approfondie du sujet\n- Solutions pratiques\n- Recommandations d\'experts\n\n### Section 3 : Conclusion\n- Synth√®se des points cl√©s\n- Actions recommand√©es\n- Perspectives d\'√©volution\n\n*Document g√©n√©r√© par l\'IA r√©dactrice le ' + new Date().toLocaleDateString('fr-FR') + '*\n\nüìÅ Souhaitez-vous que je sauvegarde ce document dans votre Drive projet (dossier IA) ?\n' +
      (userMessage.toLowerCase().includes('planning') || userMessage.toLowerCase().includes('calendrier') ? '\nFormat sugg√©r√©: Excel (.xlsx) pour les donn√©es structur√©es' :
       userMessage.toLowerCase().includes('rapport') || userMessage.toLowerCase().includes('analyse') ? '\nFormat sugg√©r√©: PDF (.pdf) pour les rapports formels' :
       userMessage.toLowerCase().includes('tableau') || userMessage.toLowerCase().includes('donn√©es') ? '\nFormat sugg√©r√©: CSV (.csv) pour les donn√©es' :
       '\nFormat sugg√©r√©: Word (.docx) pour les documents texte')
    ]
  }

  const promptResponses = responses[promptName] || responses['Concepteur r√©dacteur IA']
  const randomResponse = promptResponses[Math.floor(Math.random() * promptResponses.length)]

  return randomResponse
}