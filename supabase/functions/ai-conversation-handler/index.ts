import { serve } from "https://deno.land/std@0.168.0/http/server.ts"
import { createClient } from 'https://esm.sh/@supabase/supabase-js@2'

const corsHeaders = {
  'Access-Control-Allow-Origin': '*',
  'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type',
}

serve(async (req) => {
  if (req.method === 'OPTIONS') {
    return new Response(null, { headers: corsHeaders })
  }

  try {
    const { promptId, projectId, userMessage, conversationHistory } = await req.json()

    console.log('ü§ñ G√©n√©ration r√©ponse IA:', {
      promptId,
      projectId,
      messageLength: userMessage?.length || 0
    })

    const supabaseClient = createClient(
      Deno.env.get('SUPABASE_URL') ?? '',
      Deno.env.get('SUPABASE_SERVICE_ROLE_KEY') ?? ''
    )

    // 1. R√©cup√©rer le prompt IA
    const { data: prompt, error: promptError } = await supabaseClient
      .from('prompts_ia')
      .select('name, context, prompt, active')
      .eq('id', promptId)
      .eq('active', true)
      .single()

    if (promptError || !prompt) {
      console.error('‚ùå Prompt IA non trouv√©:', promptError)
      return new Response(JSON.stringify({
        success: false,
        error: 'Prompt IA non configur√©'
      }), {
        headers: { ...corsHeaders, 'Content-Type': 'application/json' },
        status: 400,
      })
    }

    console.log('‚úÖ Prompt IA trouv√©:', prompt.name)

    // 2. Construire le contexte de conversation avec m√©moire compl√®te
    const historyText = conversationHistory
      ?.slice(0, 8) // Utiliser jusqu'√† 8 messages pour plus de contexte
      ?.map(msg => {
        const senderName = msg.sender_name || msg.sender_email?.split('@')[0] || 'Utilisateur'
        return `${senderName}: ${msg.content}`
      })
      ?.join('\n') || ''

    // 3. Construire le prompt complet avec m√©moire de conversation
    const systemPrompt = `${prompt.prompt}

IMPORTANT - M√©moire de conversation:
Vous avez une conversation continue avec cet utilisateur. Vous devez :
- Vous souvenir du contexte et des sujets pr√©c√©demment discut√©s
- Faire r√©f√©rence aux √©changes pr√©c√©dents quand c'est pertinent
- Maintenir la coh√©rence dans vos r√©ponses
- Adapter votre ton en fonction de la relation √©tablie

Historique de la conversation (du plus ancien au plus r√©cent):
${historyText}

Nouveau message de l'utilisateur: ${userMessage}

Instructions:
- R√©pondez en fran√ßais
- Tenez compte de l'historique de conversation
- Soyez coh√©rent avec vos r√©ponses pr√©c√©dentes
- Si vous produisez un contenu long (article, document), structurez-le clairement
- Gardez un ton professionnel mais personnalis√© selon le contexte

IMPORTANT - Gestion des livrables:
Si l'utilisateur demande un livrable (article, planning, guide, rapport, documentation, etc.):
1. Produisez le contenu demand√© de mani√®re compl√®te et structur√©e
2. √Ä la fin, demandez TOUJOURS : "üìÅ Souhaitez-vous que je sauvegarde ce document dans votre Drive projet (dossier IA) au format Word (.docx) ?"
3. Si l'utilisateur r√©pond oui/ok/d'accord, ajoutez √† la fin de votre message:
   [SAVE_TO_DRIVE: nom_du_fichier.docx]
   o√π nom_du_fichier est un nom descriptif bas√© sur le contenu (ex: article_marketing_digital.docx, planning_projet_2025.docx)`

    // 4. Appel √† OpenAI (simul√© pour l'instant)
    // TODO: Remplacer par un vrai appel OpenAI avec la cl√© API configur√©e
    const openaiApiKey = Deno.env.get('OPENAI_API_KEY')

    if (!openaiApiKey) {
      console.warn('‚ö†Ô∏è Cl√© OpenAI non configur√©e, utilisation d\'une r√©ponse simul√©e')

      // R√©ponse simul√©e pour le d√©veloppement
      const simulatedResponse = generateSimulatedResponse(userMessage, prompt.name)

      return new Response(JSON.stringify({
        success: true,
        response: simulatedResponse,
        promptUsed: prompt.name,
        simulated: true
      }), {
        headers: { ...corsHeaders, 'Content-Type': 'application/json' },
      })
    }

    // Appel r√©el OpenAI
    const openaiResponse = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${openaiApiKey}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: 'gpt-4',
        messages: [
          {
            role: 'system',
            content: systemPrompt
          }
        ],
        max_tokens: 1500,
        temperature: 0.7,
      }),
    })

    if (!openaiResponse.ok) {
      throw new Error(`OpenAI API error: ${openaiResponse.statusText}`)
    }

    const openaiData = await openaiResponse.json()
    const aiResponse = openaiData.choices?.[0]?.message?.content

    if (!aiResponse) {
      throw new Error('Aucune r√©ponse g√©n√©r√©e par OpenAI')
    }

    console.log('‚úÖ R√©ponse IA g√©n√©r√©e:', aiResponse.length, 'caract√®res')

    return new Response(JSON.stringify({
      success: true,
      response: aiResponse,
      promptUsed: prompt.name,
      tokensUsed: openaiData.usage?.total_tokens || 0
    }), {
      headers: { ...corsHeaders, 'Content-Type': 'application/json' },
    })

  } catch (error) {
    console.error('‚ùå Erreur g√©n√©ration IA:', error)
    return new Response(JSON.stringify({
      success: false,
      error: error.message
    }), {
      headers: { ...corsHeaders, 'Content-Type': 'application/json' },
      status: 500,
    })
  }
})

// Fonction pour g√©n√©rer une r√©ponse simul√©e pendant le d√©veloppement
function generateSimulatedResponse(userMessage: string, promptName: string): string {
  const responses = {
    'Concepteur r√©dacteur IA': [
      `# Article de blog : ${userMessage.slice(0, 50)}

En tant que concepteur r√©dacteur IA, je vous propose ce contenu structur√© :

## Introduction
Votre demande "${userMessage}" soul√®ve des points int√©ressants que nous allons explorer en d√©tail.

## D√©veloppement
- Point 1 : Analyse de la probl√©matique
- Point 2 : Solutions propos√©es
- Point 3 : Mise en ≈ìuvre pratique

## Conclusion
Ce contenu r√©pond √† votre demande en proposant une approche m√©thodique et professionnelle.

*Article g√©n√©r√© par l'IA r√©dactrice - ${new Date().toLocaleDateString('fr-FR')}*`,

      `Voici ma r√©ponse en tant qu'IA sp√©cialis√©e en r√©daction :

${userMessage}

Je peux vous aider √† d√©velopper ce sujet plus en d√©tail si vous le souhaitez. N'h√©sitez pas √† me demander des pr√©cisions ou des contenus sp√©cifiques comme :
- Articles de blog
- Documentation technique
- Guides utilisateur
- Rapports d'analyse

Comment puis-je vous assister davantage ?`,

      `üìù **Contenu r√©dactionnel g√©n√©r√©**

Sujet trait√© : ${userMessage}

Je viens de traiter votre demande. Si vous souhaitez que je produise un document plus complet (guide, article, rapport), merci de me le pr√©ciser et je cr√©erai un contenu structur√© qui sera automatiquement sauvegard√© dans votre Drive.

Types de contenus que je peux cr√©er :
- Articles de blog optimis√©s SEO
- Guides √©tape par √©tape
- Rapports d'analyse
- Documentation projet
- Pr√©sentations commerciales

Quelle est votre pr√©f√©rence ?`
    ]
  }

  const promptResponses = responses[promptName] || responses['Concepteur r√©dacteur IA']
  const randomResponse = promptResponses[Math.floor(Math.random() * promptResponses.length)]

  return randomResponse
}