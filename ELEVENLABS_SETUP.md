# Configuration ElevenLabs Conversational AI

## üö® Configuration Requise

Pour utiliser le mode vocal avec ElevenLabs Conversational AI, vous devez :

### 1. Cr√©er un Agent Conversationnel

1. Connectez-vous sur [ElevenLabs](https://elevenlabs.io)
2. Allez dans [Conversational AI](https://elevenlabs.io/app/conversational-ai)
3. Cliquez sur "Create Agent"
4. Configurez votre agent :
   - **Name**: "Test de Comp√©tences IA"
   - **System Prompt**: Configurez le comportement de votre agent
   - **Voice**: Choisissez une voix fran√ßaise
   - **Language**: French
   - **First Message**: Message d'accueil de l'agent

### 2. R√©cup√©rer l'Agent ID

1. Une fois l'agent cr√©√©, cliquez dessus
2. Copiez l'Agent ID (format: `abc123def456...`)
3. Remplacez `your-agent-id-here` dans le fichier :
   - `/src/components/candidate/VoiceChatElevenLabsSDK.tsx`

### 3. Configuration de l'Agent

Dans les param√®tres de l'agent, activez :
- **Advanced > Client Events** : Activez les √©v√©nements n√©cessaires
- **Authentication** : Laissez d√©sactiv√© pour un agent public (tests)

## üîß Probl√®mes Actuels et Solutions

### Probl√®me 1: Voix Multiples qui se Superposent
**Cause**: Le composant actuel utilise l'API TTS simple au lieu du SDK conversationnel.
**Solution**: Utiliser le SDK `@elevenlabs/react` avec `useConversation`.

### Probl√®me 2: Micro qui ne se R√©active pas
**Cause**: La reconnaissance vocale native et ElevenLabs entrent en conflit.
**Solution**: Le SDK g√®re automatiquement le turn-taking (tour de parole).

### Probl√®me 3: Conversation qui se Coupe
**Cause**: Gestion manuelle de la reconnaissance vocale.
**Solution**: Le SDK maintient une connexion WebRTC stable.

## üì¶ Installation des D√©pendances

```bash
# Si pas d√©j√† install√©
npm install @elevenlabs/react
```

## üéØ Utilisation Correcte du SDK

```tsx
import { useConversation } from '@elevenlabs/react';

const conversation = useConversation({
  onConnect: () => console.log('Connected'),
  onDisconnect: () => console.log('Disconnected'),
  onMessage: (message) => {
    // message.type peut √™tre :
    // - 'user_transcript': Transcription de l'utilisateur
    // - 'agent_response': R√©ponse de l'agent
    // - 'audio': Audio de l'agent (g√©r√© automatiquement)
  },
  onError: (error) => console.error(error)
});

// D√©marrer la conversation
await conversation.startSession({
  agentId: 'your-agent-id',
  userId: 'optional-user-id'
});

// Arr√™ter la conversation
await conversation.endSession();
```

## ‚úÖ Avantages du SDK vs API Simple

| Fonctionnalit√© | API Simple (Actuel) | SDK Conversationnel |
|----------------|-------------------|-------------------|
| Turn-taking | Manuel (probl√©matique) | Automatique |
| Latence | √âlev√©e (~2-3s) | Faible (<500ms) |
| Gestion audio | Manuelle (queues) | Automatique |
| Interruptions | Difficiles | Natives |
| Stabilit√© | Variable | Excellente |
| WebRTC | Non | Oui |

## üîÑ Migration du Code

### Avant (Probl√©matique)
```tsx
// Reconnaissance vocale native
const recognition = new SpeechRecognition();
// TTS s√©par√©
fetch('https://api.elevenlabs.io/v1/text-to-speech/...')
// Gestion manuelle des √©tats
```

### Apr√®s (Solution)
```tsx
// Tout est g√©r√© par le SDK
const conversation = useConversation();
await conversation.startSession({ agentId });
// Le SDK g√®re automatiquement :
// - La reconnaissance vocale
// - La synth√®se vocale
// - Le turn-taking
// - Les interruptions
```

## üìù Notes Importantes

1. **Agent ID**: Sans un agent ID valide, le mode vocal ne fonctionnera pas.
2. **Microphone**: L'acc√®s au microphone est requis.
3. **WebRTC**: Utilise WebRTC pour une latence minimale.
4. **Turn-taking**: L'agent d√©tecte automatiquement quand vous avez fini de parler.

## üöÄ Prochaines √âtapes

1. Cr√©ez votre agent sur ElevenLabs
2. Remplacez l'Agent ID dans le code
3. Testez avec le nouveau composant `VoiceChatElevenLabsSDK`
4. Supprimez l'ancien composant `VoiceChatElevenLabsSimplified`