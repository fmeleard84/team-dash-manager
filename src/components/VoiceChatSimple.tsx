import { useState, useRef, useEffect } from 'react';
import { Button } from '@/components/ui/button';
import { Badge } from '@/components/ui/badge';
import { Mic, MicOff, Volume2 } from 'lucide-react';
import { toast } from 'sonner';
import { supabase } from '@/integrations/supabase/client';

interface VoiceChatSimpleProps {
  onTranscription: (text: string) => void;
  botResponse?: string;
  isEnabled: boolean;
  onToggle: () => void;
}

export function VoiceChatSimple({ onTranscription, botResponse, isEnabled, onToggle }: VoiceChatSimpleProps) {
  const [isListening, setIsListening] = useState(false);
  const [isSpeaking, setIsSpeaking] = useState(false);
  const [status, setStatus] = useState<'ready' | 'listening' | 'speaking'>('ready');
  
  const recognitionRef = useRef<any>(null);
  const audioRef = useRef<HTMLAudioElement | null>(null);
  const isPlayingRef = useRef(false);
  const isStartingRef = useRef(false);
  const shouldRestartRef = useRef(true);

  // Initialiser la reconnaissance vocale Web Speech API
  useEffect(() => {
    if (!isEnabled) {
      stopListening();
      return;
    }

    // V√©rifier le support de la Web Speech API
    const SpeechRecognition = (window as any).webkitSpeechRecognition || (window as any).SpeechRecognition;
    
    if (!SpeechRecognition) {
      toast.error('Votre navigateur ne supporte pas la reconnaissance vocale');
      onToggle();
      return;
    }

    // Cr√©er et configurer la reconnaissance
    const recognition = new SpeechRecognition();
    recognition.continuous = true;
    recognition.interimResults = false; // Seulement les r√©sultats finaux
    recognition.lang = 'fr-FR';
    recognition.maxAlternatives = 1;

    recognition.onstart = () => {
      console.log('üéôÔ∏è Reconnaissance d√©marr√©e');
      setIsListening(true);
      setStatus('listening');
      isStartingRef.current = false;
    };

    recognition.onresult = (event: any) => {
      const last = event.results.length - 1;
      const transcript = event.results[last][0].transcript;
      
      console.log('üìù Transcription:', transcript);
      
      // Arr√™ter temporairement l'√©coute pendant le traitement
      shouldRestartRef.current = false; // Emp√™cher le red√©marrage automatique
      recognition.stop();
      setIsListening(false);
      setStatus('ready');
      
      // R√©activer le red√©marrage apr√®s un d√©lai
      setTimeout(() => {
        shouldRestartRef.current = true;
      }, 100);
      
      // Envoyer la transcription
      if (transcript.trim()) {
        onTranscription(transcript);
      }
    };

    recognition.onerror = (event: any) => {
      // Ignorer les erreurs 'aborted' qui sont normales lors de l'arr√™t
      if (event.error === 'aborted') {
        console.log('üîÑ Reconnaissance interrompue (normal)');
        return;
      }
      
      console.error('‚ùå Erreur reconnaissance:', event.error);
      
      // G√©rer les erreurs communes
      if (event.error === 'not-allowed') {
        toast.error('Permission du microphone refus√©e');
        shouldRestartRef.current = false;
        onToggle();
      } else if (event.error === 'no-speech') {
        // Pas de parole d√©tect√©e, c'est normal
        console.log('üîá Pas de parole d√©tect√©e');
      } else if (event.error === 'network') {
        toast.error('Erreur r√©seau - v√©rifiez votre connexion');
      }
      
      isStartingRef.current = false;
    };

    recognition.onend = () => {
      console.log('üîö Reconnaissance termin√©e');
      setIsListening(false);
      isStartingRef.current = false;
      
      // Red√©marrer seulement si n√©cessaire
      if (isEnabled && !isPlayingRef.current && shouldRestartRef.current && !isStartingRef.current) {
        setTimeout(() => {
          if (isEnabled && !isPlayingRef.current && shouldRestartRef.current && !isStartingRef.current) {
            try {
              isStartingRef.current = true;
              recognition.start();
            } catch (e) {
              console.log('Impossible de red√©marrer la reconnaissance');
              isStartingRef.current = false;
            }
          }
        }, 1000); // D√©lai plus long pour √©viter les boucles
      }
    };

    recognitionRef.current = recognition;
    
    // D√©marrer l'√©coute avec un petit d√©lai pour √©viter les conflits
    setTimeout(() => {
      if (isEnabled && !isStartingRef.current) {
        try {
          isStartingRef.current = true;
          recognition.start();
        } catch (error) {
          console.error('Erreur d√©marrage reconnaissance:', error);
          isStartingRef.current = false;
        }
      }
    }, 100);

    return () => {
      shouldRestartRef.current = false;
      if (recognitionRef.current) {
        try {
          recognitionRef.current.abort(); // Utiliser abort() au lieu de stop()
        } catch (e) {
          console.log('Reconnaissance d√©j√† arr√™t√©e');
        }
        recognitionRef.current = null;
      }
    };
  }, [isEnabled, onTranscription, onToggle]);

  // Arr√™ter l'√©coute
  const stopListening = () => {
    if (recognitionRef.current) {
      try {
        recognitionRef.current.stop();
      } catch (e) {
        console.log('Reconnaissance d√©j√† arr√™t√©e');
      }
    }
    setIsListening(false);
    setStatus('ready');
  };

  // Lire les r√©ponses du bot avec OpenAI TTS
  useEffect(() => {
    if (!isEnabled || !botResponse || isPlayingRef.current) return;
    
    playBotResponse(botResponse);
  }, [botResponse, isEnabled]);

  const playBotResponse = async (text: string) => {
    if (isPlayingRef.current) return;
    
    try {
      console.log('üîä Lecture de la r√©ponse:', text.substring(0, 50) + '...');
      
      // Marquer comme en cours de lecture
      isPlayingRef.current = true;
      setIsSpeaking(true);
      setStatus('speaking');
      
      // Arr√™ter la reconnaissance pendant que l'IA parle
      if (recognitionRef.current) {
        try {
          recognitionRef.current.stop();
        } catch (e) {
          console.log('Reconnaissance d√©j√† arr√™t√©e');
        }
      }
      
      // Nettoyer le texte (enlever les ** pour le markdown)
      const cleanText = text.replace(/\*\*/g, '').substring(0, 1000);
      
      // Appeler OpenAI TTS via notre edge function
      const response = await supabase.functions.invoke('skill-test-ai', {
        body: {
          action: 'tts',
          text: cleanText
        }
      });
      
      if (response.data?.audio) {
        // Cr√©er et jouer l'audio
        const audioBlob = new Blob(
          [Uint8Array.from(atob(response.data.audio), c => c.charCodeAt(0))],
          { type: 'audio/mp3' }
        );
        const audioUrl = URL.createObjectURL(audioBlob);
        const audio = new Audio(audioUrl);
        audioRef.current = audio;
        
        // Quand l'audio se termine
        audio.onended = () => {
          console.log('‚úÖ Lecture termin√©e');
          URL.revokeObjectURL(audioUrl);
          isPlayingRef.current = false;
          setIsSpeaking(false);
          setStatus('ready');
          audioRef.current = null;
          
          // Red√©marrer l'√©coute apr√®s un court d√©lai
          if (isEnabled && recognitionRef.current) {
            setTimeout(() => {
              if (isEnabled && recognitionRef.current && !isPlayingRef.current && !isStartingRef.current) {
                try {
                  isStartingRef.current = true;
                  recognitionRef.current.start();
                  console.log('üéôÔ∏è √âcoute red√©marr√©e apr√®s r√©ponse');
                } catch (e) {
                  console.log('Impossible de red√©marrer apr√®s r√©ponse');
                  isStartingRef.current = false;
                }
              }
            }, 1000); // D√©lai plus long apr√®s la r√©ponse
          }
        };
        
        // G√©rer les erreurs
        audio.onerror = () => {
          console.error('‚ùå Erreur lecture audio');
          isPlayingRef.current = false;
          setIsSpeaking(false);
          setStatus('ready');
          audioRef.current = null;
          
          // Red√©marrer l'√©coute m√™me en cas d'erreur
          if (isEnabled && recognitionRef.current) {
            setTimeout(() => {
              if (isEnabled && recognitionRef.current && !isPlayingRef.current && !isStartingRef.current) {
                try {
                  isStartingRef.current = true;
                  recognitionRef.current.start();
                } catch (e) {
                  console.log('Impossible de red√©marrer apr√®s erreur audio');
                  isStartingRef.current = false;
                }
              }
            }, 1000);
          }
        };
        
        // Jouer l'audio
        await audio.play();
        console.log('‚ñ∂Ô∏è Audio en cours de lecture');
      }
    } catch (error) {
      console.error('Erreur lecture audio:', error);
      isPlayingRef.current = false;
      setIsSpeaking(false);
      setStatus('ready');
      
      // Fallback sur la synth√®se vocale native du navigateur
      try {
        const utterance = new SpeechSynthesisUtterance(text.replace(/\*\*/g, ''));
        utterance.lang = 'fr-FR';
        utterance.rate = 1.1; // Un peu plus rapide
        
        utterance.onend = () => {
          isPlayingRef.current = false;
          setIsSpeaking(false);
          setStatus('ready');
          
          // Red√©marrer l'√©coute
          if (isEnabled && recognitionRef.current) {
            setTimeout(() => {
              if (isEnabled && recognitionRef.current && !isPlayingRef.current && !isStartingRef.current) {
                try {
                  isStartingRef.current = true;
                  recognitionRef.current.start();
                } catch (e) {
                  console.log('Impossible de red√©marrer apr√®s synth√®se native');
                  isStartingRef.current = false;
                }
              }
            }, 1000);
          }
        };
        
        speechSynthesis.speak(utterance);
        console.log('üîä Fallback sur synth√®se native');
      } catch (fallbackError) {
        console.error('Erreur synth√®se vocale native:', fallbackError);
      }
    }
  };

  // Nettoyer √† la d√©sactivation
  useEffect(() => {
    if (!isEnabled) {
      // Emp√™cher les red√©marrages
      shouldRestartRef.current = false;
      isStartingRef.current = false;
      
      // Arr√™ter la reconnaissance
      if (recognitionRef.current) {
        try {
          recognitionRef.current.abort();
        } catch (e) {
          console.log('Reconnaissance d√©j√† arr√™t√©e');
        }
      }
      
      // Arr√™ter l'audio en cours
      if (audioRef.current) {
        audioRef.current.pause();
        audioRef.current = null;
      }
      
      // Arr√™ter la synth√®se vocale native
      if (window.speechSynthesis) {
        window.speechSynthesis.cancel();
      }
      
      isPlayingRef.current = false;
      setIsSpeaking(false);
      setIsListening(false);
      setStatus('ready');
    } else {
      // R√©activer le flag de red√©marrage quand on active
      shouldRestartRef.current = true;
    }
  }, [isEnabled]);

  return (
    <div className="flex items-center gap-3">
      <Button
        onClick={onToggle}
        variant={isEnabled ? "default" : "outline"}
        size="sm"
        className={isEnabled ? "bg-gradient-to-r from-purple-600 to-pink-600" : ""}
      >
        {isEnabled ? (
          <>
            <Mic className="w-4 h-4 mr-2 animate-pulse" />
            Mode Vocal Actif
          </>
        ) : (
          <>
            <MicOff className="w-4 h-4 mr-2" />
            Activer Mode Vocal
          </>
        )}
      </Button>
      
      {isEnabled && (
        <div className="flex items-center gap-2">
          {status === 'speaking' ? (
            <Badge variant="secondary" className="bg-purple-500 text-white">
              <Volume2 className="w-3 h-3 mr-1 animate-pulse" />
              IA parle
            </Badge>
          ) : status === 'listening' ? (
            <Badge variant="secondary" className="bg-red-500 text-white animate-pulse">
              <Mic className="w-3 h-3 mr-1" />
              √âcoute...
            </Badge>
          ) : (
            <Badge variant="secondary" className="bg-green-500 text-white">
              ‚úì Pr√™t
            </Badge>
          )}
          
          <Badge variant="outline" className="text-xs">
            üéØ Simple
          </Badge>
        </div>
      )}
    </div>
  );
}