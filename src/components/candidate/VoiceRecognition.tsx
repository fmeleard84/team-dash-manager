import { useEffect, useRef, useState, useCallback } from 'react';
import { Button } from '@/components/ui/button';
import { Badge } from '@/components/ui/badge';
import { Mic, MicOff, Loader2 } from 'lucide-react';
import { toast } from 'sonner';

interface VoiceRecognitionProps {
  onTranscription: (text: string) => void;
  isEnabled: boolean;
  canRecord: boolean; // Si l'IA a fini de parler
}

export function VoiceRecognition({ 
  onTranscription,
  isEnabled,
  canRecord
}: VoiceRecognitionProps) {
  const [isListening, setIsListening] = useState(false);
  const [transcript, setTranscript] = useState('');
  const recognitionRef = useRef<any>(null);
  const isProcessingRef = useRef(false);

  // Initialiser la reconnaissance vocale
  const initRecognition = useCallback(() => {
    if (!('webkitSpeechRecognition' in window) && !('SpeechRecognition' in window)) {
      console.error('âŒ Reconnaissance vocale non supportÃ©e');
      toast.error('Votre navigateur ne supporte pas la reconnaissance vocale');
      return null;
    }

    const SpeechRecognition = (window as any).webkitSpeechRecognition || (window as any).SpeechRecognition;
    const recognition = new SpeechRecognition();
    
    // Configuration
    recognition.continuous = true; // Ã‰coute continue
    recognition.interimResults = true; // RÃ©sultats intermÃ©diaires
    recognition.lang = 'fr-FR'; // FranÃ§ais
    recognition.maxAlternatives = 1;

    // Ã‰vÃ©nements
    recognition.onstart = () => {
      console.log('ðŸŽ¤ Ã‰coute dÃ©marrÃ©e');
      setIsListening(true);
      setTranscript('');
      isProcessingRef.current = false;
    };

    recognition.onresult = (event: any) => {
      let finalTranscript = '';
      let interimTranscript = '';

      for (let i = event.resultIndex; i < event.results.length; i++) {
        const transcript = event.results[i][0].transcript;
        if (event.results[i].isFinal) {
          finalTranscript += transcript + ' ';
        } else {
          interimTranscript += transcript;
        }
      }

      // Afficher la transcription temporaire
      if (interimTranscript) {
        setTranscript(interimTranscript);
      }

      // Si on a une transcription finale
      if (finalTranscript && !isProcessingRef.current) {
        console.log('ðŸ“ Transcription finale:', finalTranscript);
        const cleanedTranscript = finalTranscript.trim();
        
        // Envoyer automatiquement aprÃ¨s un silence
        if (cleanedTranscript.length > 2) { // Au moins 2 caractÃ¨res
          isProcessingRef.current = true;
          
          // ArrÃªter la reconnaissance et envoyer le texte
          setTimeout(() => {
            if (recognitionRef.current) {
              recognitionRef.current.stop();
            }
            console.log('ðŸ“¤ Envoi de la transcription:', cleanedTranscript);
            onTranscription(cleanedTranscript);
            setTranscript('');
            isProcessingRef.current = false;
          }, 1000); // Attendre 1s de silence avant d'envoyer
        }
      }
    };

    recognition.onerror = (event: any) => {
      console.error('âŒ Erreur reconnaissance:', event.error);
      if (event.error === 'no-speech') {
        console.log('âš ï¸ Aucune parole dÃ©tectÃ©e');
      } else if (event.error === 'aborted') {
        console.log('âš ï¸ Reconnaissance interrompue');
      } else {
        toast.error(`Erreur: ${event.error}`);
      }
      setIsListening(false);
    };

    recognition.onend = () => {
      console.log('ðŸ›‘ Ã‰coute terminÃ©e');
      setIsListening(false);
      isProcessingRef.current = false;
      
      // RedÃ©marrer automatiquement si on peut encore enregistrer
      if (isEnabled && canRecord) {
        setTimeout(() => {
          if (!isListening && recognitionRef.current) {
            try {
              recognitionRef.current.start();
              console.log('ðŸ”„ RedÃ©marrage automatique de l\'Ã©coute');
            } catch (e) {
              console.log('âš ï¸ Ã‰coute dÃ©jÃ  en cours');
            }
          }
        }, 500);
      }
    };

    return recognition;
  }, [onTranscription, isEnabled, canRecord]);

  // DÃ©marrer l'Ã©coute
  const startListening = useCallback(() => {
    if (!canRecord) {
      console.log('âš ï¸ Attendez que l\'IA finisse de parler');
      return;
    }

    if (!recognitionRef.current) {
      recognitionRef.current = initRecognition();
    }

    if (recognitionRef.current && !isListening) {
      try {
        recognitionRef.current.start();
        console.log('ðŸŽ™ï¸ DÃ©marrage de l\'Ã©coute...');
      } catch (error) {
        console.error('âŒ Erreur dÃ©marrage:', error);
        // Si dÃ©jÃ  en cours, on arrÃªte et redÃ©marre
        recognitionRef.current.stop();
        setTimeout(() => {
          recognitionRef.current.start();
        }, 100);
      }
    }
  }, [canRecord, isListening, initRecognition]);

  // ArrÃªter l'Ã©coute
  const stopListening = useCallback(() => {
    if (recognitionRef.current && isListening) {
      recognitionRef.current.stop();
      
      // Envoyer la transcription actuelle si elle existe
      if (transcript.trim()) {
        onTranscription(transcript.trim());
        setTranscript('');
      }
    }
  }, [isListening, transcript, onTranscription]);

  // GÃ©rer l'activation automatique
  useEffect(() => {
    if (isEnabled && canRecord && !isListening) {
      // DÃ©marrer automatiquement quand l'IA a fini de parler
      const timer = setTimeout(() => {
        startListening();
      }, 500); // Petit dÃ©lai pour Ã©viter les conflits
      
      return () => clearTimeout(timer);
    } else if (!isEnabled && isListening) {
      stopListening();
    }
  }, [isEnabled, canRecord, isListening, startListening, stopListening]);

  // Nettoyer Ã  la destruction
  useEffect(() => {
    return () => {
      if (recognitionRef.current) {
        recognitionRef.current.stop();
        recognitionRef.current = null;
      }
    };
  }, []);

  return (
    <div className="flex items-center gap-3">
      {isEnabled && (
        <>
          {isListening ? (
            <Badge variant="secondary" className="bg-red-500 text-white animate-pulse">
              <Mic className="w-3 h-3 mr-1" />
              Ã‰coute en cours...
            </Badge>
          ) : canRecord ? (
            <Badge variant="secondary" className="bg-blue-500 text-white">
              <Mic className="w-3 h-3 mr-1" />
              PrÃªt Ã  Ã©couter
            </Badge>
          ) : (
            <Badge variant="secondary" className="bg-gray-500 text-white">
              <MicOff className="w-3 h-3 mr-1" />
              IA en train de parler
            </Badge>
          )}
        </>
      )}
    </div>
  );
}